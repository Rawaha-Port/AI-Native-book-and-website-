# باب 5: انسانی-روبوٹ تعامل اور اخلاقیات

## 5.1 تعارف
اب تک، ہماری توجہ خود روبوٹ پر مرکوز رہی ہے—اس کا ہارڈویئر، حرکت، اور اندرونی ذہانت۔ یہ باب توجہ کو روبوٹ اور ہمارے درمیان تعلقات کی طرف منتقل کرتا ہے۔ جیسے جیسے روبوٹ فیکٹری کے فرش اور لیبز سے نکل کر ہمارے گھروں، کام کی جگہوں، اور عوامی مقامات پر آ رہے ہیں، جس طرح سے وہ لوگوں کے ساتھ تعامل کرتے ہیں وہ انتہائی اہم ہو جاتا ہے۔ یہ باب انسانی-روبوٹ تعامل (HRI) کے شعبے کو متعارف کراتا ہے، یہ دریافت کرتا ہے کہ ہم ایسے روبوٹس کو کیسے ڈیزائن کر سکتے ہیں جو نہ صرف ذہین اور قابل ہوں بلکہ محفوظ، بدیہی، اور سماجی طور پر قابل قبول بھی ہوں۔ مزید برآں، ہم ان گہرے اخلاقی سوالات کا سامنا کریں گے جو خود مختار ذہین نظاموں کی ترقی کے ساتھ پیدا ہوتے ہیں۔ ہم بنیادی اخلاقی اصولوں، AI میں تعصب کے خطرے، اور انجینئرز اور ڈیزائنرز کی ذمہ داری پر بحث کریں گے کہ وہ ایسے روبوٹس بنائیں جو انسانیت کو فائدہ پہنچائیں۔

## 5.2 نظریاتی بنیادیں

### 5.2.1 انسانی-روبوٹ تعامل (HRI)
HRI ایک کثیر الشعبہ جاتی میدان ہے جو انسانوں کے ذریعے یا ان کے ساتھ استعمال کے لیے روبوٹک نظاموں کو سمجھنے، ڈیزائن کرنے، اور جانچنے کے لیے وقف ہے۔ اس کا مقصد ایسے تعاملات پیدا کرنا ہے جو فطری، موثر، اور قابل اعتماد ہوں۔

- **مواصلاتی چینلز**: موثر مواصلات HRI کا سنگ بنیاد ہے۔
    - **زبانی مواصلات**: اس میں روبوٹ کی بولنے کی صلاحیت (**اسپیچ سنتھیسز**) اور بولی جانے والی زبان کو سمجھنے کی صلاحیت (**نیچرل لینگویج انڈرسٹینڈنگ** یا NLU) دونوں شامل ہیں۔ ایک فطری آواز والی اور سیاق و سباق سے آگاہ گفتگو بنانا ایک بڑا چیلنج ہے۔
    - **غیر زبانی مواصلات**: انسان غیر زبانی اشاروں پر بہت زیادہ انحصار کرتے ہیں، اور روبوٹ بھی ایسا ہی کر سکتے ہیں۔ اس میں شامل ہیں:
        - **اشارے**: تصورات کی نشاندہی کرنے، لہرانے، یا وضاحت کرنے کے لیے بازوؤں اور ہاتھوں کا استعمال۔
        - **نظر**: توجہ یا دھیان کی نشاندہی کرنے کے لیے روبوٹ کی "آنکھوں" یا سر کو ہدایت دینا۔
        - **جسمانی زبان**: मुद्रा کے ذریعے ارادے یا مزاج کا اظہار کرنا (جیسے مشغولیت دکھانے کے لیے آگے جھکنا)۔

- **سماجی اشارے اور "انکینی ویلی"**:
    - ایک روبوٹ کو قبول کیے جانے کے لیے، خاص طور پر سماجی کرداروں میں، اسے انسانی سماجی اصولوں پر عمل کرنا چاہیے۔ اس میں ذاتی جگہ کو سمجھنا، گفتگو میں باری لینا، اور مناسب جذبات کا اظہار کرنا شامل ہے۔
    - **انکینی ویلی**: یہ HRI میں ایک مشہور مفروضہ ہے۔ یہ کہتا ہے کہ جیسے جیسے ایک روبوٹ کی ظاہری شکل زیادہ انسانی جیسی ہوتی جاتی ہے، ہمارا جذباتی ردعمل تیزی سے مثبت اور ہمدردانہ ہوتا جاتا ہے۔ تاہم، اگر روبوٹ *تقریباً* بالکل انسان جیسا ہو جائے لیکن اس میں معمولی خامیاں ہوں، تو ہمارا ردعمل شدید نفرت میں گر جاتا ہے۔ وابستگی میں یہ گراوٹ "انکینی ویلی" ہے۔ مثالوں میں CGI کردار یا اینڈرائڈز شامل ہیں جو انسان کے قریب ہیں لیکن تھوڑا "عجیب" حرکت کرتے یا نظر آتے ہیں۔ اس وادی سے بچنا ہیومنائڈ روبوٹس کے ڈیزائنرز کے لیے ایک کلیدی چیلنج ہے۔

### 5.2.2 روبوٹ اخلاقیات
جیسے جیسے ہم خود مختار نظاموں کو زیادہ فیصلے تفویض کرتے ہیں، ہمیں ان میں اخلاقی اصولوں کو شامل کرنا چاہیے تاکہ یہ یقینی بنایا جا سکے کہ وہ انسانیت کے بہترین مفادات میں کام کرتے ہیں۔

- **آسیموف کے روبوٹکس کے تین قوانین**:
    1. ایک روبوٹ کسی انسان کو زخمی نہیں کر سکتا یا، بے عملی کے ذریعے، کسی انسان کو نقصان پہنچنے کی اجازت نہیں دے سکتا۔
    2. ایک روبوٹ کو انسانوں کے دیے گئے احکامات کی تعمیل کرنی چاہیے سوائے اس کے کہ ایسے احکامات پہلے قانون سے متصادم ہوں۔
    3. ایک روبوٹ کو اپنے وجود کی حفاظت کرنی چاہیے جب تک کہ ایسی حفاظت پہلے یا دوسرے قانون سے متصادم نہ ہو۔
    جبکہ یہ قوانین ایک شاندار ادبی آلہ ہیں، وہ براہ راست نافذ کرنے کے لیے بہت مبہم ہیں۔ مثال کے طور پر، "نقصان" کیا ہے؟ ایک روبوٹ دو قوانین کے درمیان تصادم کو کیسے حل کرتا ہے؟ حقیقی دنیا کی اخلاقیات کہیں زیادہ پیچیدہ ہیں۔

- **AI اور روبوٹکس میں کلیدی اخلاقی اصول**:
    - **فائدہ مندی اور غیر مضرت**: "اچھا کرو" اور "نقصان نہ پہنچاؤ" کے اصول۔ ایک روبوٹ کو ایک فائدہ مند مقصد کے لیے ڈیزائن کیا جانا چاہیے اور تمام ممکنہ خطرات کی نشاندہی اور ان کو کم کیا جانا چاہیے۔
    - **خودمختاری**: روبوٹس کو انسانی خودمختاری کو کمزور نہیں کرنا چاہیے۔ ایک نظام کو مدد کرنی چاہیے، زبردستی نہیں، اور انسانوں کو روبوٹ کے فیصلوں کو اوور رائیڈ کرنے کی صلاحیت ہونی چاہیے۔
    - **انصاف اور غیر جانبداری**: روبوٹکس کے فوائد سب کے لیے قابل رسائی ہونے چاہئیں، اور نظام خود منصفانہ ہونے چاہئیں۔ اس میں یہ یقینی بنانا شامل ہے کہ AI میں امتیازی تعصبات نہ ہوں۔
    - **رازداری**: کیمروں اور مائیکروفونز سے لیس ہیومنائڈ روبوٹس، طاقتور نگرانی کے آلات ہیں۔ انہیں مضبوط رازداری کے تحفظات کے ساتھ ڈیزائن کرنا اخلاقی طور پر لازمی ہے، یہ یقینی بنانا کہ ڈیٹا محفوظ ہے، جہاں ممکن ہو گمنام ہے، اور صرف باخبر رضامندی کے ساتھ جمع کیا جاتا ہے۔

### 5.2.3 روبوٹکس میں تعصب اور غیر جانبداری
ایک AI صرف اتنا ہی اچھا ہے جتنا کہ وہ ڈیٹا جس پر اسے تربیت دی گئی ہے۔ اگر ڈیٹا سماجی تعصبات کی عکاسی کرتا ہے، تو روبوٹ ان تعصبات کو سیکھے گا اور انہیں برقرار رکھے گا۔
- **تعصب کے ذرائع**:
    - **ڈیٹا تعصب**: اگر ایک چہرے کی شناخت کا نظام بنیادی طور پر ایک ڈیموگرافک گروپ کی تصاویر پر تربیت یافتہ ہے، تو یہ دوسروں پر خراب کارکردگی کا مظاہرہ کر سکتا ہے، جس سے غیر منصفانہ نتائج برآمد ہوتے ہیں۔
    - **الگورتھمک تعصب**: جس طرح سے ایک الگورتھم ڈیزائن کیا گیا ہے وہ نادانستہ طور پر کچھ نتائج کی حمایت کر سکتا ہے۔
- **نتائج**: ایک متعصب روبوٹ کسی شخص کے حکم کو پہچاننے میں ناکام ہو سکتا ہے, انہیں غلط شناخت کر سکتا ہے، یا وسائل کو غیر منصفانہ طور پر تقسیم کر سکتا ہے۔
- **تدارک**: غیر جانبداری کو یقینی بنانے کے لیے شعوری کوشش کی ضرورت ہے، جس میں متنوع اور نمائندہ تربیتی ڈیٹا اکٹھا کرنا، متعصب نتائج کے لیے الگورتھمز کا آڈٹ کرنا، اور شفافیت اور جوابدہی کے لیے میکانزم بنانا شامل ہے۔

## 5.3 عملی اطلاقات اور مثالیں

### 5.3.1 سماجی روبوٹس: پیپر اور جیبو
- **پیپر**: تجارتی ترتیبات میں HRI کے لیے ڈیزائن کیا گیا، پیپر ایک دوستانہ، غیر دھمکی آمیز ظاہری شکل اور انسانی جذبات اور تقریر کا پتہ لگانے اور اس پر ردعمل ظاہر کرنے کے لیے مختلف قسم کے سینسرز کا استعمال کرتا ہے۔ اس کا بنیادی کام مصروفیت ہے۔
- **جیبو**: "دنیا کا پہلا سماجی روبوٹ برائے گھر" کے طور پر مارکیٹ کیا گیا، جیبو کو ایک خاندانی ساتھی کے طور پر ڈیزائن کیا گیا تھا۔ اس کا ایک اظہاری "چہرہ" تھا اور وہ خاندان کے افراد کو پہچان سکتا تھا۔ اگرچہ ایک تجارتی ناکامی، جیبو گھر کے ماحول میں طویل مدتی HRI میں ایک اہم تجربہ تھا۔

### 5.3.2 باہمی تعاون کے روبوٹس ("کوبوٹس")
کوبوٹس کو ایک مشترکہ کام کی جگہ، عام طور پر مینوفیکچرنگ میں، انسانوں کے ساتھ محفوظ طریقے سے کام کرنے کے لیے ڈیزائن کیا گیا ہے۔ روایتی صنعتی روبوٹس کے برعکس جنہیں پنجروں میں رکھا جاتا ہے، یونیورسل روبوٹس جیسے کوبوٹس فورس سینسنگ صلاحیتوں سے لیس ہیں (اکثر سیریز الاسٹک ایکچویٹرز کا استعمال کرتے ہوئے) جو انہیں کسی شخص سے رابطہ کرنے پر فوری طور پر رکنے کی اجازت دیتے ہیں، غیر مضرت کے اصول کو مجسم کرتے ہوئے۔

### 5.3.3 اخلاقی مخمصے: خود مختار گاڑیوں کے لیے "ٹرالی کا مسئلہ"
کلاسک "ٹرالی کا مسئلہ" AI کے دور کے لیے ڈھال لیا گیا ہے۔ ایک خود مختار گاڑی ایک مکین کے ساتھ چلا رہی ہے جب اس کے بریک فیل ہو جاتے ہیں۔ یہ یا تو سیدھا چل سکتی ہے اور پانچ پیدل چلنے والوں کے ایک گروپ کو ٹکر مار سکتی ہے، یا مڑ کر ایک شخص کو ٹکر مار سکتی ہے۔ کار کو "فیصلہ" کرنے کے لیے کیسے پروگرام کیا جانا چاہیے؟ کوئی آسان جواب نہیں ہے، اور یہ سوچ کا تجربہ خود مختار نظاموں کو پروگرام کرنے میں گہرے اخلاقی چیلنجوں کو اجاگر کرتا ہے جنہیں زندگی یا موت کے انتخاب کرنے پڑ سکتے ہیں۔

## 5.4 عملی مشقیں

### مشق 5.1: "انکینی ویلی"
1. ایک روبوٹ یا CGI کردار کی تصویر یا ویڈیو تلاش کریں جس کے بارے میں آپ کو یقین ہے کہ وہ انکینی ویلی میں آتا ہے (جیسے فلموں میں ابتدائی CGI کردار، کچھ حقیقت پسندانہ اینڈرائڈز)۔ بیان کریں کہ کون سی مخصوص خصوصیات (آنکھیں، حرکت، جلد کی ساخت) اسے بے چین کرتی ہیں۔
2. ایک روبوٹ یا کردار کی مثال تلاش کریں جو انتہائی اسٹائلائزڈ اور دوستانہ ہو (جیسے WALL-E) اور ایک جو بہت حقیقت پسندانہ ہو لیکن کامیابی سے وادی سے بچتا ہو۔ وضاحت کریں کہ کون سے ڈیزائن کے انتخاب نے انہیں دلکش بنانے کی اجازت دی۔

### مشق 5.2: اپنا روبوٹ "ضابطہ اخلاق" بنائیں
مندرجہ ذیل مخصوص قسم کے روبوٹس میں سے ایک کے لیے 3-5 اخلاقی اصولوں کا ایک سیٹ تیار کریں۔ آپ کے اصول آسیموف کے قوانین سے زیادہ عملی اور کم مبہم ہونے چاہئیں۔ ہر اصول کی اہمیت کا جواز پیش کریں کہ یہ آپ کے منتخب کردہ روبوٹ کے لیے کیوں اہم ہے۔
- ایک ہسپتال کے لیے ایک ہیومنائڈ روبوٹ اسسٹنٹ۔
- شہر کے فٹ پاتھوں کے لیے ایک چھوٹا، خود مختار ڈیلیوری روبوٹ۔
- آن لائن سماجی پلیٹ فارمز کے لیے ایک روبوٹ ماڈریٹر۔

## 5.5 پروگرامنگ لیب

### 5.5.1 ماحول کو ترتیب دینا
یہ لیب تصوراتی ہے اور کسی نئی لائبریری کی ضرورت نہیں ہے۔ ہم منطق کو سمیولیٹ کرنے کے لیے بنیادی Python کا استعمال کریں گے۔

### 5.5.2 کوڈ کا ٹکڑا: ایک سادہ سماجی تعامل کو سمیولیٹ کرنا
یہ اسکرپٹ ایک سادہ اسٹیٹ مشین کو ظاہر کرتا ہے جو ایک روبوٹ کے سماجی رویے کو کنٹرول کر سکتی ہے۔ "روبوٹ" ایک صارف کو سلام کرے گا اور اس کی بنیاد پر مختلف طریقے سے جواب دے گا کہ آیا صارف کا ان پٹ مثبت، منفی، یا غیر جانبدار ہے۔ یہ واضح کرتا ہے کہ کس طرح سادہ اصول سماجی بیداری کی ظاہری شکل پیدا کر سکتے ہیں۔

```python
import time
import random

def get_user_input(prompt):
    """A function to simulate getting input from a user."""
    print(f"[USER]: {prompt}")
    time.sleep(1)
    return prompt

def robot_say(message):
    """A function to simulate the robot speaking."""
    print(f"[ROBOT]: {message}")
    time.sleep(1)

def analyze_sentiment(text):
    """A simple function to simulate sentiment analysis."""
    text = text.lower()
    if "good" in text or "great" in text or "fine" in text:
        return "positive"
    elif "bad" in text or "terrible" in text or "not good" in text:
        return "negative"
    else:
        return "neutral"

def run_social_interaction():
    # State: "GREETING"
    robot_say("Hello! I am a service robot. How is your day going?")
    
    # Get user response and transition state
    user_response = get_user_input(random.choice(["It's going great, thanks!", "Not very good.", "It's okay."]))
    
    sentiment = analyze_sentiment(user_response)
    
    # State: "RESPONDING_TO_SENTIMENT"
    if sentiment == "positive":
        robot_say("I'm glad to hear that! Is there anything I can help you with today?")
    elif sentiment == "negative":
        robot_say("I'm sorry to hear that. I hope it gets better. Please let me know if there's anything I can do to help.")
    else: # neutral
        robot_say("I see. Let me know if there is anything I can do to make it better.")

    # State: "TASK_MODE"
    robot_say("I can tell you the weather, a joke, or the time.")
    user_request = get_user_input(random.choice(["What's the weather like?", "Tell me a joke."]))
    
    if "weather" in user_request.lower():
        robot_say("It is sunny with a high of 25 degrees Celsius.")
    elif "joke" in user_request.lower():
        robot_say("Why don't scientists trust atoms? Because they make up everything!")
    else:
        robot_say(f"The current time is {time.strftime('%H:%M')}.")

    # State: "FAREWELL"
    robot_say("Have a wonderful day!")

if __name__ == "__main__":
    run_social_interaction()

```
**وضاحت:**
- یہ اسکرپٹ روبوٹ کی تقریر، صارف کی تقریر، اور ایک جذبات کے تجزیے کے ماڈیول کو سمیولیٹ کرنے کے لیے فنکشنز کا استعمال کرتا ہے۔
- `run_social_interaction` فنکشن ایک سادہ "اسٹیٹ مشین" کی پیروی کرتا ہے۔ یہ `GREETING` حالت سے `RESPONDING_TO_SENTIMENT` حالت، اور آخر میں `TASK_MODE` حالت میں منتقل ہوتا ہے۔
- یہ ظاہر کرتا ہے کہ کس طرح بہت سادہ منطق بھی ایک زیادہ دلچسپ اور بظاہر ذہین تعامل پیدا کر سکتی ہے بمقابلہ ایک روبوٹ جو صرف احکامات کا انتظار کرتا ہے۔

## 5.6 باب کا خلاصہ
اس باب نے ٹیکنالوجی اور انسانیت کے اہم سنگم کا جائزہ لیا۔ ہم نے انسانی-روبوٹ تعامل (HRI) کو اس شعبے کے طور پر بیان کیا جو روبوٹس کو لوگوں کے لیے موثر اور فطری شراکت دار بنانے کے لیے وقف ہے، جس میں زبانی اور غیر زبانی دونوں مواصلات پر توجہ مرکوز ہے۔ ہم نے ان گہری اخلاقی ذمہ داریوں کا بھی سامنا کیا جو خود مختار مشینیں بنانے کے ساتھ آتی ہیں۔ ہم نے فائدہ مندی، انصاف، اور رازداری جیسے بنیادی اصولوں پر بحث کی، اور جانچا کہ کس طرح ڈیٹا میں تعصبات غیر منصفانہ نتائج کا باعث بن سکتے ہیں۔ کیس اسٹڈیز اور مشقوں کے ذریعے، ہم نے دیکھا ہے کہ ایک اچھا روبوٹ بنانا صرف ایک تکنیکی چیلنج نہیں ہے—یہ ایک انسانیت سوز چیلنج ہے۔ ایک حقیقی طور پر جدید روبوٹ نہ صرف قابل ہے بلکہ ہمدرد، محفوظ، اور انسانی اقدار کا احترام کرنے والا بھی ہے۔

## 5.7 مزید مطالعہ
-   **کتابیں**:
    -   `دی میڈیا ایکویشن: ہاؤ پیپل ٹریٹ کمپیوٹرز، ٹیلی ویژن، اینڈ نیو میڈیا لائک ریئل پیپل اینڈ پلیسز` از بائرن ریوز اور کلفورڈ ناس۔
    -   `روبوٹ ایتھکس 2.0: فرام آٹونومس کارز ٹو آرٹیفیشل انٹیلیجنس`، ترمیم شدہ از پیٹرک لن، ریان جینکنز، اور کیتھ ایبنی۔
    -   `ویپنز آف میتھ ڈسٹرکشن: ہاؤ بگ ڈیٹا انکریزز ان ایکویلٹی اینڈ تھریٹنز ڈیموکریسی` از کیتھی او نیل۔
-   **مقالے**:
    -   "دی انکینی ویلی" از ماساہیرو موری (اصل مضمون)۔
    -   "ACM/IEEE انٹرنیشنل کانفرنس آن ہیومن-روبوٹ انٹریکشن (HRI)" سے حالیہ مقالے تلاش کریں۔
